## 인공신경망과 딥러닝 HW2 - Pytorch를 사용한 MNIST 분류
### 기계정보공학과 24510091 안정민

이 저장소는 PyTorch를 사용하여 MNIST 데이터셋을 분류하는 다양한 신경망 모델의 구현을 포함하고 있습니다.

## 데이터셋

학습 및 테스트에 사용되는 데이터셋은 손으로 쓴 숫자로 구성된 MNIST 데이터셋입니다.

### 전처리

데이터셋은 다음과 같이 전처리됩니다:

- 각 이미지는 흑백으로 변환됩니다.
- 이미지 픽셀의 값은 [0,1] 범위로 정규화됩니다.
- 각 픽셀에서 0.1307의 평균이 뺀 후 0.3081의 표준 편차로 나눕니다.

## 모델

이 작업을 위해 다음과 같은 신경망 모델들이 구현되었습니다:

1. **LeNet-5**: Yann LeCun 등에 의해 1998년에 제안된 클래식 합성곱 신경망 구조입니다.
2. **Custom MLP**: 완전 연결 계층으로 구성된 사용자 정의 다층 퍼셉트론 모델입니다.
3. **LeNet5re1**: 배치 정규화가 추가된 LeNet-5의 변형입니다.
4. **LeNet5re2**: 배치 정규화와 드롭아웃이 추가된 LeNet-5의 변형입니다.

### 모델 구조

- **LeNet-5**:
  - Conv1: 1 입력 채널, 6 출력 채널, 커널 크기 5x5, 스트라이드 1
  - Conv2: 6 입력 채널, 16 출력 채널, 커널 크기 5x5, 스트라이드 1
  - FC 계층: 120, 84, 출력 단위 수를 클래스의 수로 설정된 출력 계층
  - 총 파라미터 수: 44,426

- **Custom MLP**:
  - 완전 연결 계층: 28x28에서 70, 70에서 50, 50에서 클래스의 수로
  - 총 파라미터 수: 59,010 (LeNet-5의 파라미터 수와 비슷하게 모델 작성)

- **LeNet5re1**:
  - 배치 정규화가 각 합성곱 계층 뒤에 추가된 LeNet-5와 동일한 구조

- **LeNet5re2**:
  - 완전 연결 계층 뒤에 배치 정규화와 드롭아웃이 추가된 LeNet-5와 동일한 구조

## 학습

모델은 모멘텀을 가진 확률적 경사 하강법(SGD)을 사용하여 학습됩니다. 학습 및 검증 손실 및 정확도는 분석을 위해 로그에 기록됩니다.

### 학습 결과

10 에포크 학습 후, 테스트 결과는 다음과 같습니다:

- **LeNet-5**: 
  - 테스트 손실: 0.0378
  - 테스트 정확도: 98.85%
  
- **Custom MLP**: 
  - 테스트 손실: 0.0874
  - 테스트 정확도: 97.61%

- **LeNet5re1**: 
  - 테스트 손실: 0.0337
  - 테스트 정확도: 99.01%

- **LeNet5re2**: 
  - 테스트 손실: 0.0305
  - 테스트 정확도: 99.09%

## 파일

- `dataset.py`: MNIST를 위한 사용자 정의 데이터셋 클래스를 포함합니다.
- `model.py`: 신경망 아키텍처를 정의합니다.
- `main.py`: 모델을 학습하고 평가하는 주요 스크립트입니다.

## 종속성

- PyTorch
- torchvision
- matplotlib
- pandas

## 사용 방법

코드를 실행하려면:

```bash
python main.py
```
